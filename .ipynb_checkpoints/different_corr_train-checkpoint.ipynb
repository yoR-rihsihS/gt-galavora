{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je_J76ALDQ2Q"
   },
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zM6fXNueDRhh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D78VG9hDDYQ9"
   },
   "source": [
    "# Setting Hyper-Parameters For Model and data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmVlW1KfX2Iu"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "\n",
    "num_epochs = 3000\n",
    "batch_size = 1024\n",
    "num_validation_batches = 8\n",
    "num_agents = 4\n",
    "prob = 0.2\n",
    "\n",
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiWt6eKi8qDl"
   },
   "source": [
    "# Generating Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZW5X0EPI8Zun"
   },
   "outputs": [],
   "source": [
    "def generate_permutation_array(N, num_agents):\n",
    "    P = np.zeros((N, num_agents))\n",
    "    for i in range(N):\n",
    "        P[i] = np.random.permutation(num_agents)\n",
    "    return P\n",
    "\n",
    "\n",
    "class Data(object):\n",
    "    \"\"\"\n",
    "    A class for generating data for the matching problem\n",
    "    \"\"\"\n",
    "    def __init__(self, num_agents, prob, corr):\n",
    "        self.num_agents = num_agents\n",
    "        self.prob = prob\n",
    "        self.corr = corr\n",
    "\n",
    "\n",
    "    def sample_ranking(self, N, prob):\n",
    "        \"\"\"\n",
    "        Samples ranked lists\n",
    "        Arguments\n",
    "            N: Number of samples\n",
    "            prob: Probability of truncation\n",
    "        Returns:\n",
    "            Ranked List of shape [N, Num_agents]\n",
    "        \"\"\"\n",
    "        N_trunc = int(N * prob)\n",
    "        P = generate_permutation_array(N, self.num_agents) + 1\n",
    "\n",
    "        if N_trunc > 0:\n",
    "            # Choose indices to truncate\n",
    "            idx = np.random.choice(N, N_trunc, replace = False)\n",
    "\n",
    "            # Choose a position to truncate\n",
    "            trunc = np.random.randint(self.num_agents, size = N_trunc)\n",
    "\n",
    "            # Normalize so preference to remain single has 0 payoff\n",
    "            swap_vals = P[idx, trunc]\n",
    "            P[idx, trunc] = 0\n",
    "            P[idx] = P[idx] - swap_vals[:, np.newaxis]\n",
    "\n",
    "        return P/self.num_agents\n",
    "\n",
    "\n",
    "    def generate_all_ranking(self, include_truncation = True):\n",
    "        \"\"\"\n",
    "        Generates all possible rankings\n",
    "        Arguments\n",
    "            include_truncation: Whether to include truncations or only generate complete rankings\n",
    "        Returns:\n",
    "            Ranked of list of shape: [m, num_agents]\n",
    "                where m = N! if complete, (N+1)! if truncations are included\n",
    "        \"\"\"\n",
    "        if include_truncation is False:\n",
    "            M = np.array(list(itertools.permutations(np.arange(self.num_agents)))) + 1.0\n",
    "        else:\n",
    "            M = np.array(list(itertools.permutations(np.arange(self.num_agents + 1))))\n",
    "            M = (M - M[:, -1:])[:, :-1]\n",
    "\n",
    "        return M/self.num_agents\n",
    "\n",
    "\n",
    "    def generate_batch(self, batch_size, prob = None, corr = None):\n",
    "        \"\"\"\n",
    "        Samples a batch of data from training\n",
    "        Arguments\n",
    "            batch_size: number of samples\n",
    "            prob: probability of truncation\n",
    "        Returns\n",
    "            P: Men's preferences,\n",
    "                P_{ij}: How much Man-i prefers to be with Women-j\n",
    "            Q: Women's preferences,\n",
    "                Q_{ij}: How much Woman-j prefers to be with Man-i\n",
    "        \"\"\"\n",
    "        if corr is None: corr = self.corr\n",
    "        if prob is None: prob = self.prob\n",
    "\n",
    "        N = batch_size * self.num_agents\n",
    "\n",
    "        P = self.sample_ranking(N, prob)\n",
    "        Q = self.sample_ranking(N, prob)\n",
    "\n",
    "        P = P.reshape(-1, self.num_agents, self.num_agents)\n",
    "        Q = Q.reshape(-1, self.num_agents, self.num_agents)\n",
    "\n",
    "        if corr > 0.00:\n",
    "            P_common = self.sample_ranking(batch_size, prob).reshape(batch_size, 1, self.num_agents)\n",
    "            Q_common = self.sample_ranking(batch_size, prob).reshape(batch_size, 1, self.num_agents)\n",
    "\n",
    "            P_idx = np.random.binomial(1, corr, [batch_size, self.num_agents, 1])\n",
    "            Q_idx = np.random.binomial(1, corr, [batch_size, self.num_agents, 1])\n",
    "\n",
    "            P = P * (1 - P_idx) + P_common * P_idx\n",
    "            Q = Q * (1 - Q_idx) + Q_common * Q_idx\n",
    "\n",
    "        Q = Q.transpose(0, 2, 1)\n",
    "\n",
    "        return P, Q\n",
    "\n",
    "\n",
    "    def compose_misreport(self, P, Q, M, agent_idx, is_P = True):\n",
    "        \"\"\" Composes mis-report\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            M: Ranked List of mis_reports\n",
    "                    either [num_misreports, num_agents]\n",
    "                    or [batch_size, num_misreports, num_agents]\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, num_misreports, num_agents, num_agents]\n",
    "\n",
    "        \"\"\"\n",
    "        num_misreports = M.shape[-2]\n",
    "        P_mis = np.tile(P[:, None, :, :], [1, num_misreports, 1, 1])\n",
    "        Q_mis = np.tile(Q[:, None, :, :], [1, num_misreports, 1, 1])\n",
    "\n",
    "        if is_P: P_mis[:, :, agent_idx, :] = M\n",
    "        else: Q_mis[:, :, :, agent_idx] = M\n",
    "\n",
    "        return P_mis, Q_mis\n",
    "\n",
    "\n",
    "    def generate_all_misreports(self, P, Q, agent_idx, is_P, include_truncation = True):\n",
    "        \"\"\" Generates all mis-reports\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "            include_truncation: Whether to truncate preference or submit complete preferences\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, M, num_agents, num_agents]\n",
    "                where M = (num_agents + 1)! if truncations are includes\n",
    "                      M = (num_agents)! if preferences are complete\n",
    "        \"\"\"\n",
    "        M = self.generate_all_ranking(include_truncation = include_truncation)\n",
    "        P_mis, Q_mis = self.compose_misreport(P, Q, M, agent_idx, is_P)\n",
    "\n",
    "        return P_mis, Q_mis\n",
    "\n",
    "\n",
    "    def sample_misreports(self, P, Q, num_misreports_per_sample, agent_idx, is_P, prob = None):\n",
    "        \"\"\" Samples misreports\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            num_misreports_per_sample: Number of misreports per sample\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "            prob: probability of truncation\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, num_misreports_per_sample, num_agents, num_agents]\n",
    "        \"\"\"\n",
    "        if prob is None: prob = self.prob\n",
    "\n",
    "        N = P.shape[0]\n",
    "        M = self.sample_ranking(N * num_misreports_per_sample, prob).reshape(N, num_misreports_per_sample, -1)\n",
    "        P_mis, Q_mis = self.compose_misreport(P, Q, M, agent_idx, is_P)\n",
    "\n",
    "        return P_mis, Q_mis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM01cH-p8Z7L"
   },
   "source": [
    "# Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJiJ_x4E8avq"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\" Neural Network Module for Matching \"\"\"\n",
    "    def __init__(self, num_agents=4, num_hidden_nodes=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_agents = num_agents\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "\n",
    "        self.input_block = nn.Sequential(\n",
    "            # Input Layer\n",
    "            nn.Linear(2 * (num_agents**2), num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 1\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 2\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 3\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 4\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU())\n",
    "\n",
    "        # Output Layer\n",
    "        self.layer_out_r = nn.Linear(num_hidden_nodes, (num_agents + 1) * num_agents)\n",
    "        self.layer_out_c = nn.Linear(num_hidden_nodes, num_agents * (num_agents + 1))\n",
    "\n",
    "\n",
    "    def forward(self, p, q):\n",
    "\n",
    "        p = F.relu(p)\n",
    "        q = F.relu(q)\n",
    "\n",
    "        x = torch.stack([p, q], axis = -1)\n",
    "        x = x.view(-1, self.num_agents * self.num_agents * 2)\n",
    "        x = self.input_block(x)\n",
    "\n",
    "        mask_p = (p > 0).to(p.dtype)\n",
    "        mask_p = F.pad(mask_p, (0, 0, 0, 1, 0, 0), mode='constant', value=1)\n",
    "\n",
    "        mask_q = (q > 0).to(q.dtype)\n",
    "        mask_q = F.pad(mask_q, (0, 1, 0, 0, 0, 0), mode='constant', value=1)\n",
    "\n",
    "        x_r = self.layer_out_r(x)\n",
    "        x_r = x_r.view(-1, self.num_agents + 1, self.num_agents)\n",
    "        x_c = self.layer_out_c(x)\n",
    "        x_c = x_c.view(-1, self.num_agents, self.num_agents + 1)\n",
    "\n",
    "        x_r = F.softplus(x_r) * mask_p\n",
    "        x_c = F.softplus(x_c) * mask_q\n",
    "\n",
    "        x_r = F.normalize(x_r, p = 1, dim = 1, eps=1e-8)\n",
    "        x_c = F.normalize(x_c, p = 1, dim = 2, eps=1e-8)\n",
    "\n",
    "        return torch.min(x_r[:, :-1, :], x_c[:, :, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SF4beMmUrgS"
   },
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQ9cbyEy84os"
   },
   "outputs": [],
   "source": [
    "# Stability Violation\n",
    "def compute_st(r, p, q):\n",
    "    wp = F.relu(p[:, :, None, :] - p[:, :, :, None])\n",
    "    wq = F.relu(q[:, :, None, :] - q[:, None, :, :], 0)\n",
    "    t = (1 - torch.sum(r, dim = 1, keepdim = True))\n",
    "    s = (1 - torch.sum(r, dim = 2, keepdim = True))\n",
    "    rgt_1 = torch.einsum('bjc,bijc->bic', r, wq) + t * F.relu(q)\n",
    "    rgt_2 = torch.einsum('bia,biac->bic', r, wp) + s * F.relu(p)\n",
    "    regret =  rgt_1 * rgt_2\n",
    "    return regret.sum(-1).sum(-1).mean()/num_agents\n",
    "\n",
    "# IR Violation\n",
    "def compute_ir(r, p, q):\n",
    "    ir_1 = r * F.relu(-q)\n",
    "    ir_2 = r * F.relu(-p)\n",
    "    ir = ir_1 + ir_2\n",
    "    return ir.sum(-1).sum(-1).mean()/num_agents\n",
    "\n",
    "# FOSD Violation\n",
    "def compute_ic_FOSD(r, p, q, P, Q, data_generator, r_mult = 1):\n",
    "\n",
    "    IC_viol_P = torch.zeros(num_agents).to(device)\n",
    "    IC_viol_Q = torch.zeros(num_agents).to(device)\n",
    "\n",
    "    discount = torch_var((r_mult) ** np.arange(num_agents))\n",
    "\n",
    "    for agent_idx in range(num_agents):\n",
    "        P_mis, Q_mis = data_generator.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = True, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
    "        r_mis = r_mis.view(*P_mis.shape)\n",
    "\n",
    "        r_diff = (r_mis[:, :, agent_idx, :] - r[:, None, agent_idx, :])*(p[:, None, agent_idx, :] > 0).float()\n",
    "        _, idx = torch.sort(-p[:, agent_idx, :])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "\n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_P[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "        P_mis, Q_mis = data_generator.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = False, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
    "        r_mis = r_mis.view(*Q_mis.shape)\n",
    "\n",
    "        r_diff = (r_mis[:, :, :, agent_idx] - r[:, None, :, agent_idx])*(q[:, None, :, agent_idx] > 0).float()\n",
    "        _, idx = torch.sort(-q[:, :, agent_idx])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "\n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_Q[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "    IC_viol = (IC_viol_P.mean() + IC_viol_Q.mean())*0.5\n",
    "    return IC_viol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LD1Mqjcw96DF"
   },
   "outputs": [],
   "source": [
    "def torch_var(x):\n",
    "      return torch.Tensor(x).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AtVUVlZqpj1"
   },
   "source": [
    "# Helper Function for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-FNxdxupjku"
   },
   "outputs": [],
   "source": [
    "def trainer(model, optimizer, num_epochs, batch_size, data_generator, num_validation_batches, lambd):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "        P, Q = data_generator.generate_batch(batch_size)\n",
    "\n",
    "        p, q = torch_var(P), torch_var(Q)\n",
    "        r = model(p, q)\n",
    "\n",
    "        st_loss = compute_st(r, p, q)\n",
    "        ic_loss = compute_ic_FOSD(r, p, q, P, Q, data_generator)\n",
    "\n",
    "        total_loss = st_loss * (lambd) + ic_loss * (1 - lambd)\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        del P, Q, p, q, r\n",
    "\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(\"Epoch -\", epoch+1, \"Train --- (Stability Violation, IC Violation, Total Loss) =\", (st_loss.item(), ic_loss.item(), total_loss.item()))\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_st_loss = 0.0\n",
    "                val_ic_loss = 0.0\n",
    "                for j in range(num_validation_batches):\n",
    "                    P, Q = data_generator.generate_batch(batch_size)\n",
    "                    p, q = torch_var(P), torch_var(Q)\n",
    "                    r = model(p, q)\n",
    "\n",
    "                    st_loss = compute_st(r, p, q)\n",
    "                    ic_loss = compute_ic_FOSD(r, p, q, P, Q, data_generator)\n",
    "                    val_st_loss += st_loss.item()\n",
    "                    val_ic_loss += ic_loss.item()\n",
    "\n",
    "                    del P, Q, p, q, r\n",
    "\n",
    "\n",
    "            print(\"Epoch -\", epoch+1, \"Validation --- (Stability Violation, IC Violation) =\", (val_st_loss/num_validation_batches, val_ic_loss/num_validation_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prKOLg9sUXjv"
   },
   "source": [
    "# Training All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yU-y4e6Cpjz6",
    "outputId": "9fb8926b-b7db-443d-e8cb-3ce1af02527a"
   },
   "outputs": [],
   "source": [
    "# Set of lambdas to train for\n",
    "lambdas = [1.0, 0.75, 0.5, 0.25, 0.0]\n",
    "\n",
    "# Set of correlation values for generating different data\n",
    "corrs = [0.00, 0.25, 0.50, 0.75]\n",
    "old_paths = [\"/models_7k/c00/\", \"/models_7k/c25/\", \"/models_7k/c50/\", \"/models_7k/c75/\"]\n",
    "paths = [\"/models_10k/c00/\", \"/models_10k/c25/\", \"/models_10k/c50/\", \"/models_10k/c75/\"]\n",
    "\n",
    "for i in range(len(corrs)):\n",
    "    data_generator = Data(num_agents = num_agents, prob = prob, corr = corrs[i])\n",
    "\n",
    "    for lambd in lambdas:       \n",
    "        model = Net()\n",
    "        model.to(device)\n",
    "        \n",
    "        model.load_state_dict(torch.load(PATH + old_paths[i] + str(lambd) + \".pt\", map_location = device))\n",
    "     \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0005)\n",
    "        \n",
    "        trainer(model, optimizer, num_epochs, batch_size, data_generator, num_validation_batches, lambd)\n",
    "\n",
    "        if not os.path.exists(PATH + paths[i]):\n",
    "            os.makedirs(PATH + paths[i])\n",
    "\n",
    "        torch.save(model.state_dict(), PATH + paths[i] + str(lambd) + \".pt\")\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyG-CZ0tpj2G"
   },
   "outputs": [],
   "source": [
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
