{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\"\n",
    "\n",
    "batch_size = 1024\n",
    "num_validation_batches = 32\n",
    "num_agents = 4\n",
    "prob = 0.2 \n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5495d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutation_array(N, num_agents):\n",
    "    P = np.zeros((N, num_agents))\n",
    "    for i in range(N):\n",
    "        P[i] = np.random.permutation(num_agents)\n",
    "    return P\n",
    "\n",
    "\n",
    "class Data(object):\n",
    "    \"\"\"\n",
    "    A class for generating data for the matching problem\n",
    "    \"\"\"\n",
    "    def __init__(self, num_agents, prob, corr):\n",
    "        self.num_agents = num_agents\n",
    "        self.prob = prob\n",
    "        self.corr = corr\n",
    "\n",
    "\n",
    "    def sample_ranking(self, N, prob):\n",
    "        \"\"\"\n",
    "        Samples ranked lists\n",
    "        Arguments\n",
    "            N: Number of samples\n",
    "            prob: Probability of truncation\n",
    "        Returns:\n",
    "            Ranked List of shape [N, Num_agents]\n",
    "        \"\"\"\n",
    "        N_trunc = int(N * prob)\n",
    "        P = generate_permutation_array(N, self.num_agents) + 1\n",
    "\n",
    "        if N_trunc > 0:\n",
    "            # Choose indices to truncate\n",
    "            idx = np.random.choice(N, N_trunc, replace = False)\n",
    "\n",
    "            # Choose a position to truncate\n",
    "            trunc = np.random.randint(self.num_agents, size = N_trunc)\n",
    "\n",
    "            # Normalize so preference to remain single has 0 payoff\n",
    "            swap_vals = P[idx, trunc]\n",
    "            P[idx, trunc] = 0\n",
    "            P[idx] = P[idx] - swap_vals[:, np.newaxis]\n",
    "\n",
    "        return P/self.num_agents\n",
    "\n",
    "\n",
    "    def generate_all_ranking(self, include_truncation = True):\n",
    "        \"\"\"\n",
    "        Generates all possible rankings\n",
    "        Arguments\n",
    "            include_truncation: Whether to include truncations or only generate complete rankings\n",
    "        Returns:\n",
    "            Ranked of list of shape: [m, num_agents]\n",
    "                where m = N! if complete, (N+1)! if truncations are included\n",
    "        \"\"\"\n",
    "        if include_truncation is False:\n",
    "            M = np.array(list(itertools.permutations(np.arange(self.num_agents)))) + 1.0\n",
    "        else:\n",
    "            M = np.array(list(itertools.permutations(np.arange(self.num_agents + 1))))\n",
    "            M = (M - M[:, -1:])[:, :-1]\n",
    "\n",
    "        return M/self.num_agents\n",
    "\n",
    "\n",
    "    def generate_batch(self, batch_size, prob = None, corr = None):\n",
    "        \"\"\"\n",
    "        Samples a batch of data from training\n",
    "        Arguments\n",
    "            batch_size: number of samples\n",
    "            prob: probability of truncation\n",
    "        Returns\n",
    "            P: Men's preferences,\n",
    "                P_{ij}: How much Man-i prefers to be Women-j\n",
    "            Q: Women's preferences,\n",
    "                Q_{ij}: How much Woman-j prefers to be with Man-i\n",
    "        \"\"\"\n",
    "        if corr is None: corr = self.corr\n",
    "        if prob is None: prob = self.prob\n",
    "\n",
    "        N = batch_size * self.num_agents\n",
    "\n",
    "        P = self.sample_ranking(N, prob)\n",
    "        Q = self.sample_ranking(N, prob)\n",
    "\n",
    "        P = P.reshape(-1, self.num_agents, self.num_agents)\n",
    "        Q = Q.reshape(-1, self.num_agents, self.num_agents)\n",
    "\n",
    "        if corr > 0.00:\n",
    "            P_common = self.sample_ranking(batch_size, prob).reshape(batch_size, 1, self.num_agents)\n",
    "            Q_common = self.sample_ranking(batch_size, prob).reshape(batch_size, 1, self.num_agents)\n",
    "\n",
    "            P_idx = np.random.binomial(1, corr, [batch_size, self.num_agents, 1])\n",
    "            Q_idx = np.random.binomial(1, corr, [batch_size, self.num_agents, 1])\n",
    "\n",
    "            P = P * (1 - P_idx) + P_common * P_idx\n",
    "            Q = Q * (1 - Q_idx) + Q_common * Q_idx\n",
    "\n",
    "        Q = Q.transpose(0, 2, 1)\n",
    "\n",
    "        return P, Q\n",
    "\n",
    "\n",
    "    def compose_misreport(self, P, Q, M, agent_idx, is_P = True):\n",
    "        \"\"\" Composes mis-report\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            M: Ranked List of mis_reports\n",
    "                    either [num_misreports, num_agents]\n",
    "                    or [batch_size, num_misreports, num_agents]\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, num_misreports, num_agents, num_agents]\n",
    "\n",
    "        \"\"\"\n",
    "        num_misreports = M.shape[-2]\n",
    "        P_mis = np.tile(P[:, None, :, :], [1, num_misreports, 1, 1])\n",
    "        Q_mis = np.tile(Q[:, None, :, :], [1, num_misreports, 1, 1])\n",
    "\n",
    "        if is_P: P_mis[:, :, agent_idx, :] = M\n",
    "        else: Q_mis[:, :, :, agent_idx] = M\n",
    "\n",
    "        return P_mis, Q_mis\n",
    "\n",
    "\n",
    "    def generate_all_misreports(self, P, Q, agent_idx, is_P, include_truncation = True):\n",
    "        \"\"\" Generates all mis-reports\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "            include_truncation: Whether to truncate preference or submit complete preferences\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, M, num_agents, num_agents]\n",
    "                where M = (num_agents + 1)! if truncations are includes\n",
    "                      M = (num_agents)! if preferences are complete\n",
    "        \"\"\"\n",
    "        M = self.generate_all_ranking(include_truncation = include_truncation)\n",
    "        P_mis, Q_mis = self.compose_misreport(P, Q, M, agent_idx, is_P)\n",
    "\n",
    "        return P_mis, Q_mis\n",
    "\n",
    "\n",
    "    def sample_misreports(self, P, Q, num_misreports_per_sample, agent_idx, is_P, prob = None):\n",
    "        \"\"\" Samples misreports\n",
    "        Arguments:\n",
    "            P: Men's preference, [Batch_size, num_agents, num_agents]\n",
    "            Q: Women's preference [Batch_size, num_agents, num_agents]\n",
    "            num_misreports_per_sample: Number of misreports per sample\n",
    "            agent_idx: Agent-idx that is mis-reporting\n",
    "            is_P: if True, Men[agent-idx] misreporting\n",
    "                    else, Women[agent-idx] misreporting\n",
    "            prob: probability of truncation\n",
    "\n",
    "        Returns:\n",
    "            P_mis, Q_mis: [batch-size, num_misreports_per_sample, num_agents, num_agents]\n",
    "        \"\"\"\n",
    "        if prob is None: prob = self.prob\n",
    "\n",
    "        N = P.shape[0]\n",
    "        M = self.sample_ranking(N * num_misreports_per_sample, prob).reshape(N, num_misreports_per_sample, -1)\n",
    "        P_mis, Q_mis = self.compose_misreport(P, Q, M, agent_idx, is_P)\n",
    "\n",
    "        return P_mis, Q_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\" Neural Network Module for Matching \"\"\"\n",
    "    def __init__(self, num_agents=4, num_hidden_nodes=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_agents = num_agents\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "\n",
    "        self.input_block = nn.Sequential(\n",
    "            # Input Layer\n",
    "            nn.Linear(2 * (num_agents**2), num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 1\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 2\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 3\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU(),\n",
    "\n",
    "            # Layer 4\n",
    "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        # Output Layer\n",
    "        self.layer_out_r = nn.Linear(num_hidden_nodes, (num_agents + 1) * num_agents)\n",
    "        self.layer_out_c = nn.Linear(num_hidden_nodes, num_agents * (num_agents + 1))\n",
    "\n",
    "\n",
    "    def forward(self, p, q):\n",
    "\n",
    "        p = F.relu(p)\n",
    "        q = F.relu(q)\n",
    "\n",
    "        x = torch.stack([p, q], axis = -1)\n",
    "        x = x.view(-1, self.num_agents * self.num_agents * 2)\n",
    "        x = self.input_block(x)\n",
    "\n",
    "        mask_p = (p > 0).to(p.dtype)\n",
    "        mask_p = F.pad(mask_p, (0, 0, 0, 1, 0, 0), mode='constant', value=1)\n",
    "\n",
    "        mask_q = (q > 0).to(q.dtype)\n",
    "        mask_q = F.pad(mask_q, (0, 1, 0, 0, 0, 0), mode='constant', value=1)\n",
    "\n",
    "        x_r = self.layer_out_r(x)\n",
    "        x_r = x_r.view(-1, self.num_agents + 1, self.num_agents)\n",
    "        x_c = self.layer_out_c(x)\n",
    "        x_c = x_c.view(-1, self.num_agents, self.num_agents + 1)\n",
    "\n",
    "        x_r = F.softplus(x_r) * mask_p\n",
    "        x_c = F.softplus(x_c) * mask_q\n",
    "\n",
    "        x_r = F.normalize(x_r, p = 1, dim = 1, eps=1e-8)\n",
    "        x_c = F.normalize(x_c, p = 1, dim = 2, eps=1e-8)\n",
    "\n",
    "        return torch.min(x_r[:, :-1, :], x_c[:, :, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e668b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability Violation\n",
    "def compute_st(r, p, q):\n",
    "    wp = F.relu(p[:, :, None, :] - p[:, :, :, None])\n",
    "    wq = F.relu(q[:, :, None, :] - q[:, None, :, :], 0)\n",
    "    t = (1 - torch.sum(r, dim = 1, keepdim = True))\n",
    "    s = (1 - torch.sum(r, dim = 2, keepdim = True))\n",
    "    rgt_1 = torch.einsum('bjc,bijc->bic', r, wq) + t * F.relu(q)\n",
    "    rgt_2 = torch.einsum('bia,biac->bic', r, wp) + s * F.relu(p)\n",
    "    regret =  rgt_1 * rgt_2\n",
    "    return regret.sum(-1).sum(-1).mean()/num_agents\n",
    "\n",
    "# IR Violation\n",
    "def compute_ir(r, p, q):\n",
    "    ir_1 = r * F.relu(-q)\n",
    "    ir_2 = r * F.relu(-p)\n",
    "    ir = ir_1 + ir_2\n",
    "    return ir.sum(-1).sum(-1).mean()/num_agents\n",
    "\n",
    "# FOSD Violation\n",
    "def compute_ic_FOSD(r, p, q, P, Q, data_generator, r_mult = 1):\n",
    "\n",
    "    IC_viol_P = torch.zeros(num_agents).to(device)\n",
    "    IC_viol_Q = torch.zeros(num_agents).to(device)\n",
    "\n",
    "    discount = torch_var((r_mult) ** np.arange(num_agents))\n",
    "\n",
    "    for agent_idx in range(num_agents):\n",
    "        P_mis, Q_mis = data_generator.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = True, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
    "        r_mis = r_mis.view(*P_mis.shape)\n",
    "\n",
    "        r_diff = (r_mis[:, :, agent_idx, :] - r[:, None, agent_idx, :])*(p[:, None, agent_idx, :] > 0).float()\n",
    "        _, idx = torch.sort(-p[:, agent_idx, :])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "\n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_P[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "        P_mis, Q_mis = data_generator.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = False, include_truncation = True)\n",
    "        p_mis, q_mis = torch_var(P_mis), torch_var(Q_mis)\n",
    "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
    "        r_mis = r_mis.view(*Q_mis.shape)\n",
    "\n",
    "        r_diff = (r_mis[:, :, :, agent_idx] - r[:, None, :, agent_idx])*(q[:, None, :, agent_idx] > 0).float()\n",
    "        _, idx = torch.sort(-q[:, :, agent_idx])\n",
    "        idx = idx[:, None, :].repeat(1, r_mis.size(1), 1)\n",
    "\n",
    "        fosd_viol = torch.cumsum(torch.gather(r_diff, -1, idx) * discount, -1)\n",
    "        IC_viol_Q[agent_idx] = F.relu(fosd_viol).max(-1)[0].max(-1)[0].mean(-1)\n",
    "\n",
    "    IC_viol = (IC_viol_P.mean() + IC_viol_Q.mean())*0.5\n",
    "    return IC_viol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_var(x):\n",
    "      return torch.Tensor(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bce6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_generator):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_st_loss = 0.0\n",
    "        val_ic_loss = 0.0\n",
    "        welfare = 0.0\n",
    "        \n",
    "        for j in range(num_validation_batches):\n",
    "            P, Q = data_generator.generate_batch(batch_size)\n",
    "            p, q = torch_var(P), torch_var(Q)\n",
    "            r = model(p, q)\n",
    "            \n",
    "            R = r.detach().cpu().numpy()\n",
    "            welfare += (P * R + Q * R).sum()/(batch_size * num_agents * 2)\n",
    "            \n",
    "            st_loss = compute_st(r, p, q)\n",
    "            ic_loss = compute_ic_FOSD(r, p, q, P, Q, data_generator)\n",
    "            \n",
    "            val_st_loss += st_loss.item() \n",
    "            val_ic_loss += ic_loss.item()\n",
    "\n",
    "            print(\"[Batch]\", j, \"[ST_LOSS]\", st_loss.item(), \"[IC_LOSS]\", ic_loss.item())\n",
    "            \n",
    "        val_st_loss = val_st_loss/num_validation_batches\n",
    "        val_ic_loss = val_ic_loss/num_validation_batches\n",
    "        welfare = welfare/num_validation_batches\n",
    "\n",
    "        print(\"[ST_LOSS]\", val_st_loss, \"[IC_LOSS]\", val_ic_loss, \"[Welfare]\", welfare)\n",
    "        \n",
    "        return val_st_loss, val_ic_loss, welfare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "model_path = [\"./models_10k/mixed/\", \"./models_10k/c00/\", \"./models_10k/c25/\", \"./models_10k/c50/\", \"./models_10k/c75/\"]\n",
    "model_name = [\"0.0.pt\", \"0.25.pt\", \"0.5.pt\", \"0.75.pt\", \"1.0.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(m):\n",
    "    corr_values = [0.00, 0.25, 0.50, 0.75]\n",
    "    lambdas = [0.00, 0.25, 0.50, 0.75, 1.00]\n",
    "    \n",
    "    ST_LOSS = []\n",
    "    IC_LOSS = []\n",
    "    WF = []\n",
    "    for corr in corr_values:\n",
    "        data_generator = Data(num_agents = num_agents, prob = prob, corr = corr)\n",
    "\n",
    "        ST_loss = []\n",
    "        IC_loss = []\n",
    "        wel = []\n",
    "\n",
    "        for j, lambd in enumerate(lambdas):\n",
    "            model.load_state_dict(torch.load(model_path[m] + model_name[j], map_location = device))\n",
    "            st, ic, wf = validate(model, data_generator)\n",
    "            ST_loss.append(st)\n",
    "            IC_loss.append(ic)\n",
    "            wel.append(wf)\n",
    "\n",
    "        ST_LOSS.append(ST_loss)\n",
    "        IC_LOSS.append(IC_loss)\n",
    "        WF.append(wel)\n",
    "        \n",
    "    return ST_LOSS, IC_LOSS, WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = [\"mixed\", \"c00\", \"c25\", \"c50\", \"c75\"]\n",
    "for i in range(5):\n",
    "    ST_LOSS, IC_LOSS, WF = get_all_results(i)\n",
    "    result = {\"ST_LOSS\" : ST_LOSS, \"IC_LOSS\" : IC_LOSS, \"WF\" : WF}\n",
    "    \n",
    "    print(result_name[i], \"DONE.\")\n",
    "    print(\"ST_LOSS :\", ST_LOSS)\n",
    "    print(\"IC_LOSS :\", IC_LOSS)\n",
    "    print(\"WF :\", WF)\n",
    "    \n",
    "    with open(\"./models_10k/\"+result_name[i]+'_results.pkl', 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cacd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_name = [\"mixed\", \"c00\", \"c25\", \"c50\", \"c75\"]\n",
    "for i in range(5):\n",
    "    with open(\"./models_10k/\"+result_name[i]+'_results.pkl', 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    print(result_name[i]+'_results.pkl')\n",
    "    print(loaded_data[\"ST_LOSS\"])\n",
    "    print(loaded_data[\"IC_LOSS\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2ece5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
